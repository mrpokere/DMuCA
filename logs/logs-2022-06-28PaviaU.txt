creating ./logs/logs-2022-06-28PaviaU.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-06-28:20:09--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Running an experiment with the Model_by_COA model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1283 samples selected for training(over 42776)
41493 samples selected for training(over 42776)
Running an experiment with the Model_by_COA model, RUN [1/1]
RUN:0
855 samples selected for validation(over 42776)
Running an experiment with the Model_by_COA model
Train dataloader:37
Validation dataloader:24
----------Training parameters----------
dataset:PaviaU
model:Model_by_COA
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.03
train_gt:False
test_gt:False
sample_nums:20
epoch:100
save_epoch:5
patch_size:13
lr:0.005
class_balancing:True
test_stride:1
n_classes:10
ignored_labels:[0]
device:cuda:0
weights:tensor([0.0000, 0.4623, 0.1646, 1.4603, 1.0000, 2.3000, 0.6093, 2.3000, 0.8288,
        3.2857], device='cuda:0')
batch_size:32
validation_percentage:0.02
bands:103
spa_head:32
spe_head:49
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f92990474a8>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:1.91, val_acc:0.77]
Epoch [2/100    avg_loss:0.64, val_acc:0.83]
Epoch [3/100    avg_loss:0.33, val_acc:0.87]
Epoch [4/100    avg_loss:0.22, val_acc:0.94]
Epoch [5/100    avg_loss:0.14, val_acc:0.93]
Epoch [6/100    avg_loss:0.11, val_acc:0.95]
Epoch [7/100    avg_loss:0.08, val_acc:0.95]
Epoch [8/100    avg_loss:0.08, val_acc:0.96]
Epoch [9/100    avg_loss:0.12, val_acc:0.96]
Epoch [10/100    avg_loss:0.11, val_acc:0.95]
Epoch [11/100    avg_loss:0.07, val_acc:0.98]
Epoch [12/100    avg_loss:0.08, val_acc:0.97]
Epoch [13/100    avg_loss:0.09, val_acc:0.96]
Epoch [14/100    avg_loss:0.05, val_acc:0.98]
Epoch [15/100    avg_loss:0.05, val_acc:0.97]
Epoch [16/100    avg_loss:0.03, val_acc:0.98]
Epoch [17/100    avg_loss:0.01, val_acc:0.98]
Epoch [18/100    avg_loss:0.02, val_acc:0.98]
Epoch [19/100    avg_loss:0.02, val_acc:0.98]
Epoch [20/100    avg_loss:0.01, val_acc:0.99]
Epoch [21/100    avg_loss:0.01, val_acc:0.98]
Epoch [22/100    avg_loss:0.00, val_acc:0.98]
Epoch [23/100    avg_loss:0.01, val_acc:0.98]
Epoch [24/100    avg_loss:0.01, val_acc:0.98]
Epoch [25/100    avg_loss:0.01, val_acc:0.98]
Epoch [26/100    avg_loss:0.00, val_acc:0.99]
Epoch [27/100    avg_loss:0.00, val_acc:0.98]
Epoch [28/100    avg_loss:0.00, val_acc:0.98]
Epoch [29/100    avg_loss:0.00, val_acc:0.99]
Epoch [30/100    avg_loss:0.00, val_acc:0.99]
Epoch [31/100    avg_loss:0.00, val_acc:0.99]
Epoch [32/100    avg_loss:0.00, val_acc:0.99]
Epoch [33/100    avg_loss:0.00, val_acc:0.99]
Epoch [34/100    avg_loss:0.00, val_acc:0.99]
Epoch [35/100    avg_loss:0.00, val_acc:0.99]
Epoch [36/100    avg_loss:0.00, val_acc:0.99]
Epoch [37/100    avg_loss:0.02, val_acc:0.97]
Epoch [38/100    avg_loss:0.03, val_acc:0.98]
Epoch [39/100    avg_loss:0.01, val_acc:0.99]
Epoch [40/100    avg_loss:0.01, val_acc:0.98]
Epoch [41/100    avg_loss:0.01, val_acc:0.99]
Epoch [42/100    avg_loss:0.01, val_acc:0.99]
Epoch [43/100    avg_loss:0.00, val_acc:0.98]
Epoch [44/100    avg_loss:0.00, val_acc:0.98]
Epoch [45/100    avg_loss:0.00, val_acc:0.98]
Epoch [46/100    avg_loss:0.00, val_acc:0.98]
Epoch [47/100    avg_loss:0.00, val_acc:0.99]
Epoch [48/100    avg_loss:0.00, val_acc:0.99]
Epoch [49/100    avg_loss:0.00, val_acc:0.99]
Epoch [50/100    avg_loss:0.00, val_acc:0.99]
Epoch [51/100    avg_loss:0.00, val_acc:0.99]
Epoch [52/100    avg_loss:0.00, val_acc:0.99]
Epoch [53/100    avg_loss:0.00, val_acc:0.99]
Epoch [54/100    avg_loss:0.00, val_acc:0.99]
Epoch [55/100    avg_loss:0.00, val_acc:0.99]
Epoch [56/100    avg_loss:0.00, val_acc:0.99]
Epoch [57/100    avg_loss:0.00, val_acc:0.99]
Epoch [58/100    avg_loss:0.00, val_acc:0.99]
Epoch [59/100    avg_loss:0.00, val_acc:0.99]
Epoch [60/100    avg_loss:0.00, val_acc:0.99]
Epoch [61/100    avg_loss:0.00, val_acc:0.99]
Epoch [62/100    avg_loss:0.00, val_acc:0.99]
Epoch [63/100    avg_loss:0.00, val_acc:0.99]
Epoch [64/100    avg_loss:0.00, val_acc:0.98]
Epoch [65/100    avg_loss:0.00, val_acc:0.99]
Epoch [66/100    avg_loss:0.00, val_acc:0.99]
Epoch [67/100    avg_loss:0.00, val_acc:0.98]
Epoch [68/100    avg_loss:0.01, val_acc:0.98]
Epoch [69/100    avg_loss:0.01, val_acc:0.99]
Epoch [70/100    avg_loss:0.00, val_acc:0.99]
Epoch [71/100    avg_loss:0.00, val_acc:0.99]
Epoch [72/100    avg_loss:0.00, val_acc:0.99]
Epoch [73/100    avg_loss:0.00, val_acc:0.99]
Epoch [74/100    avg_loss:0.00, val_acc:0.99]
Epoch [75/100    avg_loss:0.00, val_acc:0.99]
Epoch [76/100    avg_loss:0.00, val_acc:0.99]
Epoch [77/100    avg_loss:0.00, val_acc:0.99]
Epoch [78/100    avg_loss:0.00, val_acc:0.98]
Epoch [79/100    avg_loss:0.00, val_acc:0.99]
Epoch [80/100    avg_loss:0.00, val_acc:0.99]
Epoch [81/100    avg_loss:0.00, val_acc:0.99]
Epoch [82/100    avg_loss:0.00, val_acc:0.99]
Epoch [83/100    avg_loss:0.00, val_acc:0.99]
Epoch [84/100    avg_loss:0.00, val_acc:0.99]
Epoch [85/100    avg_loss:0.00, val_acc:0.99]
Epoch [86/100    avg_loss:0.00, val_acc:0.99]
Epoch [87/100    avg_loss:0.00, val_acc:0.99]
Epoch [88/100    avg_loss:0.00, val_acc:0.99]
Epoch [89/100    avg_loss:0.00, val_acc:0.99]
Epoch [90/100    avg_loss:0.00, val_acc:0.99]
Epoch [91/100    avg_loss:0.00, val_acc:0.99]
Epoch [92/100    avg_loss:0.00, val_acc:0.99]
Epoch [93/100    avg_loss:0.00, val_acc:0.99]
Epoch [94/100    avg_loss:0.00, val_acc:0.99]
Epoch [95/100    avg_loss:0.00, val_acc:0.99]
Epoch [96/100    avg_loss:0.00, val_acc:0.99]
Epoch [97/100    avg_loss:0.00, val_acc:0.99]
Epoch [98/100    avg_loss:0.00, val_acc:0.99]
Epoch [99/100    avg_loss:0.00, val_acc:0.99]
Epoch [100/100    avg_loss:0.00, val_acc:0.99]
----------Training result----------

Confusion matrix:
[[    0     0     0     0     0     0     0     0     0     0]
 [    0  6430     0     1     1     0     0     0     0     0]
 [    0     2 18057     0    16     0     3     0    12     0]
 [    0     1     0  1971     0     0     0     0    64     0]
 [    0    30    14     7  2891     0     1     0    24     5]
 [    0     0     0     0     0  1305     0     0     0     0]
 [    0     0    49     0     0     0  4828     0     0     1]
 [    0     3     0     0     0     0     0  1285     0     2]
 [    0    15     0    24    30     0     0     0  3499     3]
 [    0     2     0     2    10     0     0     2     0   903]]

Accuracy:
99.2191

F1 scores:
[   nan 0.9957 0.9973 0.9755 0.9767 1.     0.9944 0.9973 0.976  0.9853]

Kappa:
0.9896
dataset:PaviaU
['99.57+-0.0' '99.73+-0.0' '97.55+-0.0' '97.67+-0.0' '100.0+-0.0'
 '99.44+-0.0' '99.73+-0.0' '97.6+-0.0' '98.53+-0.0']
OA_list [[99.2191454]]
OA±std 99.22 ±0.00
